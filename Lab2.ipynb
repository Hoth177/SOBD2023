{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c65e1c-be8d-47eb-89cc-ac40c19d996a",
   "metadata": {},
   "source": [
    "## Лабораторная работа №2 по дисциплине \"Системы обработки больших данных\"\n",
    "### Подключаем библиотеки и отфильтрованный датасет из ЛР № 1\n",
    "#### Постановка задачи:\n",
    "**Цель и задачи работы:**\n",
    "1. Познакомиться с базовыми алгоритмами машинного обучения;\n",
    "\n",
    "2. Познакомиться с реализацией машинного обучения в библиотеке Spark ML.\n",
    "\n",
    "3. Получить навыки разработки программного обеспечения для анализа данных с использованием pyspark.\n",
    "\n",
    "**Необходимо выполнить анализ обработанного датасета с помощью двух алгоритмов машинного обучения:**\n",
    "\n",
    "*Задача регрессии* - RandomForest\n",
    "\n",
    "*Задача бинарной классификации* - LogisticRegression\n",
    "\n",
    "**При анализе датасета предпочтительно использовать признаки, показавшие наилучшую корреляцию при выполнении разведочного анализа. Для задачи классификации использовать бинарный признак.\n",
    "Необходимо выполнить обучение и валидацию модели, рассчитайте значения метрик классификации и регрессии. Выполните подбор гиперпараметров моделей по сетке.**\n",
    "\n",
    "### Задача регрессии - RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dffb21c-66b2-47c1-a546-994b216bfc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-----------+--------------+---------+--------+---------+--------------+-------------------+----------------------------+\n",
      "|startingAirport|destinationAirport|elapsedDays|isBasicEconomy|isNonStop|baseFare|totalFare|seatsRemaining|totalTravelDistance|totalFlightDurationInSeconds|\n",
      "+---------------+------------------+-----------+--------------+---------+--------+---------+--------------+-------------------+----------------------------+\n",
      "|            ATL|               BOS|        0.0|         false|     true|  367.98|   410.18|           1.0|              947.0|                      9840.0|\n",
      "|            ATL|               DEN|        0.0|         false|    false|  262.33|   305.61|           7.0|             1375.0|                     16800.0|\n",
      "|            ATL|               DFW|        0.0|         false|    false|  174.88|    211.6|           2.0|             1399.0|                     17160.0|\n",
      "|            ATL|               MIA|        0.0|         false|    false|  503.51|   564.87|           5.0|             1866.0|                     20040.0|\n",
      "|            ATL|               OAK|        0.0|         false|    false|  528.37|    596.1|           2.0|             2393.0|                     25680.0|\n",
      "|            ATL|               PHL|        0.0|         false|     true|  636.28|    698.6|           3.0|              667.0|                      7320.0|\n",
      "|            ATL|               SFO|        0.0|         false|    false|  496.74|    557.6|           2.0|             2161.0|                     21900.0|\n",
      "|            BOS|               CLT|        0.0|         false|     true|  734.88|    804.6|           1.0|              728.0|                      8940.0|\n",
      "|            BOS|               MIA|        1.0|         false|    false|   301.4|   347.61|           1.0|             2054.0|                     22200.0|\n",
      "|            BOS|               ORD|        0.0|         false|     true|  185.58|    214.1|           1.0|              862.0|                     10620.0|\n",
      "+---------------+------------------+-----------+--------------+---------+--------+---------+--------------+-------------------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- startingAirport: string (nullable = true)\n",
      " |-- destinationAirport: string (nullable = true)\n",
      " |-- elapsedDays: double (nullable = true)\n",
      " |-- isBasicEconomy: boolean (nullable = true)\n",
      " |-- isNonStop: boolean (nullable = true)\n",
      " |-- baseFare: double (nullable = true)\n",
      " |-- totalFare: double (nullable = true)\n",
      " |-- seatsRemaining: double (nullable = true)\n",
      " |-- totalTravelDistance: double (nullable = true)\n",
      " |-- totalFlightDurationInSeconds: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "filename_data = 'processed_work/data/sampled.csv'\n",
    "df = spark.read.csv(filename_data, inferSchema=True, header=True)\n",
    "df.show(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe4245-a050-4444-a8c9-826f254fc8a9",
   "metadata": {},
   "source": [
    "##### Будем использовать только числовые признаки показавшие наилучшую корреляцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ca1b29-4acd-441b-9057-195ec510a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------+--------+---------+\n",
      "|totalFlightDurationInSeconds|totalTravelDistance|baseFare|totalFare|\n",
      "+----------------------------+-------------------+--------+---------+\n",
      "|                      9840.0|              947.0|  367.98|   410.18|\n",
      "|                     16800.0|             1375.0|  262.33|   305.61|\n",
      "|                     17160.0|             1399.0|  174.88|    211.6|\n",
      "|                     20040.0|             1866.0|  503.51|   564.87|\n",
      "|                     25680.0|             2393.0|  528.37|    596.1|\n",
      "|                      7320.0|              667.0|  636.28|    698.6|\n",
      "|                     21900.0|             2161.0|  496.74|    557.6|\n",
      "|                      8940.0|              728.0|  734.88|    804.6|\n",
      "|                     22200.0|             2054.0|   301.4|   347.61|\n",
      "|                     10620.0|              862.0|  185.58|    214.1|\n",
      "+----------------------------+-------------------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df.select(\"totalFlightDurationInSeconds\", \"totalTravelDistance\", \"baseFare\", \"totalFare\")\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcccab-3dbd-4715-a2e0-d70bb977c6db",
   "metadata": {},
   "source": [
    "#### Разделим данные на обучающую и тестовую выборку\n",
    "\n",
    "##### Будем использовать 75% данных для обучения и 25% для тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bc7cab-9b52-4f54-9110-a2e5fa8388d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные строки: 561774  Тестовые сроки: 187691\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.75, 0.25])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print(\"Тренировочные строки:\", train_rows, \" Тестовые сроки:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194c1e7-b0f8-4407-b79d-4b8b59ce8854",
   "metadata": {},
   "source": [
    "#### Определим конвейер\n",
    "##### Конвейер состоит из серии этапов преобразования и оценки, которые обычно подготавливают фрейм данных для моделирования, а затем обучают прогнозирующую модель. В этом случае создадем конвейер с двумя этапами:\n",
    "\n",
    "1. **VectorAssembler:** Создает вектор непрерывных числовых признаков.\n",
    "\n",
    "2. **RandomForest:** Обучает модель регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dade3e9-fdbc-4cac-9c0b-af29209cf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVect = VectorAssembler(inputCols = [\"totalFlightDurationInSeconds\", \"baseFare\", \"totalFare\"], outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol='totalTravelDistance')\n",
    "\n",
    "pipeline = Pipeline(stages=[numVect, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c44bd-88ae-416b-9077-a0885c92e64c",
   "metadata": {},
   "source": [
    "##### Запускаем конвейер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b76dbce-bb7b-4c61-885c-bdeff2b67ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "piplineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd7e3a-270b-40f2-9eeb-bc5e9366f6c6",
   "metadata": {},
   "source": [
    "##### Создаем предсказанные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4199ca-2151-4406-9633-5b272d7b675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------------------+\n",
      "|            features|       prediction|totalTravelDistance|\n",
      "+--------------------+-----------------+-------------------+\n",
      "|[2760.0,185.12,21...|701.3266018343759|               97.0|\n",
      "|[2880.0,147.91,17...| 635.289249234229|               97.0|\n",
      "|[2880.0,157.21,18...|618.3293170203896|               97.0|\n",
      "|[2880.0,157.21,18...|618.3293170203896|               97.0|\n",
      "|[2880.0,157.21,18...|618.3293170203896|               97.0|\n",
      "|[2880.0,199.07,22...|699.1229732911586|               97.0|\n",
      "|[2880.0,226.98,25...| 724.254770711324|               97.0|\n",
      "|[2880.0,385.12,42...|1010.290848164777|               97.0|\n",
      "|[2940.0,282.79,31...|929.2455577626982|               97.0|\n",
      "|[3120.0,166.51,19...|618.3293170203896|               97.0|\n",
      "|[3840.0,171.16,19...|644.0572175363257|              228.0|\n",
      "|[4020.0,171.16,19...|644.0572175363257|              228.0|\n",
      "|[4020.0,189.77,21...|699.1229732911586|              228.0|\n",
      "| [4080.0,45.58,63.6]|386.3850571357039|              185.0|\n",
      "| [4080.0,50.23,68.6]|386.3850571357039|              185.0|\n",
      "|[4080.0,133.95,15...|607.0468616338469|              185.0|\n",
      "| [4080.0,78.14,97.1]|519.1379342935527|              228.0|\n",
      "| [4080.0,78.14,97.1]|519.1379342935527|              228.0|\n",
      "|[4080.0,124.65,14...|597.7602398040856|              228.0|\n",
      "|[4080.0,171.16,19...|644.0572175363257|              228.0|\n",
      "+--------------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = piplineModel.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"totalTravelDistance\")\n",
    "predicted.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2cc3b-f749-4d2e-93c4-c2993f6312cc",
   "metadata": {},
   "source": [
    "##### Метрики для оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ab981a-1a8d-47e4-a982-1d8ee5798788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the RandomForest regression model is 301.71\n",
      "The MSE for the RandomForest regression model is 91030.46\n",
      "The R2 for the RandomForest regression model is 0.87\n",
      "The MAE for the RandomForest regression model is 233.95\n"
     ]
    }
   ],
   "source": [
    "rfEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"totalTravelDistance\", metricName=\"rmse\")\n",
    "# RMSE\n",
    "rmse = rfEvaluator.evaluate(prediction)\n",
    "print(f\"The RMSE for the RandomForest regression model is {rmse:0.2f}\")\n",
    "# MSE\n",
    "mse = rfEvaluator.setMetricName(\"mse\").evaluate(prediction)\n",
    "print(f\"The MSE for the RandomForest regression model is {mse:0.2f}\")\n",
    "# R2\n",
    "r2 = rfEvaluator.setMetricName(\"r2\").evaluate(prediction)\n",
    "print(f\"The R2 for the RandomForest regression model is {r2:0.2f}\")\n",
    "# MAE\n",
    "mae = rfEvaluator.setMetricName(\"mae\").evaluate(prediction)\n",
    "print(f\"The MAE for the RandomForest regression model is {mae:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de19fa-b100-42c3-98d5-c5314aaf65f6",
   "metadata": {},
   "source": [
    "##### Создадим параметрическую сетку для настройки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338ba9a3-98a0-4268-8a57-028ccca64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfparam_grid = (ParamGridBuilder()\n",
    "    .addGrid(rf.maxDepth, [2, 5, 10])\n",
    "    .addGrid(rf.maxBins, [5, 10, 20])\n",
    "    .addGrid(rf.numTrees, [5, 20, 50])\n",
    "    .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc97cca-db79-4f76-9308-8cfcf7bde4b7",
   "metadata": {},
   "source": [
    "##### Создадим кросс-валидатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b643f73-9365-4f57-9fad-1d9df6cb100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv = CrossValidator(estimator=pipeline, \\\n",
    "                    estimatorParamMaps=rfparam_grid, \\\n",
    "                    evaluator=RegressionEvaluator(\n",
    "                                predictionCol=\"prediction\", \\\n",
    "                                labelCol=\"totalTravelDistance\", \\\n",
    "                                metricName=\"rmse\"), \\\n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14900d1f-18c7-4ea3-94bc-df30577c0237",
   "metadata": {},
   "source": [
    "##### Запускаем конвейер с поиском оптимальных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e38d36-5fd8-4f7f-bd82-fc7b1f98fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcvModel = rfcv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41699470-9ffa-4bdc-9406-593cad9986fe",
   "metadata": {},
   "source": [
    "##### Создаем предсказанные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c2e2cf-4f49-47ed-a53a-a3bb83799416",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPredictions = rfcvModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46d97f-fdb7-4716-a095-6e2e7b6c79a1",
   "metadata": {},
   "source": [
    "##### Метрики для оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566b9fee-a624-4fb4-97a4-f94c9142cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the RandomForest regression model is 186.48\n",
      "The MSE for the RandomForest regression model is 60709.41\n",
      "The R2 for the RandomForest regression model is 0.92\n",
      "The MAE for the RandomForest regression model is 186.48\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = rfEvaluator.evaluate(rfPredictions)\n",
    "print(f\"The RMSE for the RandomForest regression model is {rmse:0.2f}\")\n",
    "# MSE\n",
    "mse = rfEvaluator.setMetricName(\"mse\").evaluate(rfPredictions)\n",
    "print(f\"The MSE for the RandomForest regression model is {mse:0.2f}\")\n",
    "# R2\n",
    "r2 = rfEvaluator.setMetricName(\"r2\").evaluate(rfPredictions)\n",
    "print(f\"The R2 for the RandomForest regression model is {r2:0.2f}\")\n",
    "# MAE\n",
    "mae = rfEvaluator.setMetricName(\"mae\").evaluate(rfPredictions)\n",
    "print(f\"The MAE for the RandomForest regression model is {mae:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a491e9-e45d-4f75-bb14-066d56185a89",
   "metadata": {},
   "source": [
    "### Задача классификации - LogisticRegression\n",
    "##### Используем бинарный признак isNonStop т.к. он более сбалансирован в отличии от isBasicEconomy\n",
    "Однако сначала добавим колонку label с преобразованными значениями и узнаем их соотношение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4755538a-b834-47dc-837c-f07fe39ed430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"label\", when(col(\"isNonStop\") == True, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62ca962-015d-4dda-9aa6-8383c6e1bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|211175|\n",
      "|    0|538290|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts = df.groupBy(\"label\").count()\n",
    "label_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3d5ea-b391-421f-9543-96adf1ae8dd7",
   "metadata": {},
   "source": [
    "Соотношение несбалансированное, поэтому применим oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04eefdd8-1c0c-4b0e-8f93-585805566b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "import pyspark.sql.functions as F\n",
    "# Подсчет количества элементов с меткой 1 и 0\n",
    "count_label_1 = df.filter(col(\"label\") == 1).count()\n",
    "count_label_0 = df.filter(col(\"label\") == 0).count()\n",
    "\n",
    "df_label_1 = df.filter(col(\"label\") == 1)\n",
    "\n",
    "# Определение коэффициента oversampling\n",
    "oversample_factor = int(count_label_0 / count_label_1)\n",
    "\n",
    "# Применение oversampling только к данным с label = 1\n",
    "df_oversampled_label_1 = df_label_1.withColumn(\"dummy\", F.explode(F.array([F.lit(x) for x in range(oversample_factor)]))).drop(\"dummy\")\n",
    "\n",
    "# Объединение исходного DataFrame с увеличенными данными с label = 1\n",
    "df_oversampled = df.union(df_oversampled_label_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2afbf895-1799-4aea-a7e8-a68c3dadf9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|633525|\n",
      "|    0|538290|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts = df_oversampled.groupBy(\"label\").count()\n",
    "label_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a2270-4dd3-4fbd-a981-ba47c5d62df4",
   "metadata": {},
   "source": [
    "Теперь строк с меткой 1 стало намного больше. Можем приступать к дальнейшим действиям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c9207-fb60-432b-b07f-c499b505513c",
   "metadata": {},
   "source": [
    "#### Разделим данные на обучающую и тестовую выборку\n",
    "##### Будем использовать 75% данных для обучения и 25% для тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f06c81e7-d5b9-4ec9-9f41-109e23dd6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+--------------+-------------------+----------------------------+-----+\n",
      "|elapsedDays|baseFare|totalFare|seatsRemaining|totalTravelDistance|totalFlightDurationInSeconds|label|\n",
      "+-----------+--------+---------+--------------+-------------------+----------------------------+-----+\n",
      "|        0.0|  367.98|   410.18|           1.0|              947.0|                      9840.0|    1|\n",
      "|        0.0|  262.33|   305.61|           7.0|             1375.0|                     16800.0|    0|\n",
      "|        0.0|  174.88|    211.6|           2.0|             1399.0|                     17160.0|    0|\n",
      "|        0.0|  503.51|   564.87|           5.0|             1866.0|                     20040.0|    0|\n",
      "|        0.0|  528.37|    596.1|           2.0|             2393.0|                     25680.0|    0|\n",
      "|        0.0|  636.28|    698.6|           3.0|              667.0|                      7320.0|    1|\n",
      "|        0.0|  496.74|    557.6|           2.0|             2161.0|                     21900.0|    0|\n",
      "|        0.0|  734.88|    804.6|           1.0|              728.0|                      8940.0|    1|\n",
      "|        1.0|   301.4|   347.61|           1.0|             2054.0|                     22200.0|    0|\n",
      "|        0.0|  185.58|    214.1|           1.0|              862.0|                     10620.0|    1|\n",
      "+-----------+--------+---------+--------------+-------------------+----------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df_oversampled.select(\"elapsedDays\", \"baseFare\", \"totalFare\", \"seatsRemaining\", \"totalTravelDistance\", \"totalFlightDurationInSeconds\", \"label\")\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea719e75-c0ee-436a-b8e6-2e167b1abd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные строки: 880009  Тестовые сроки: 291806\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.75, 0.25])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print(\"Тренировочные строки:\", train_rows, \" Тестовые сроки:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed20c4-acd7-4d42-8398-6fd74c97ccf0",
   "metadata": {},
   "source": [
    "#### Определим конвейер\n",
    "##### Конвейер состоит из серии этапов преобразования и оценки, которые обычно подготавливают фрейм данных для моделирования, а затем обучают прогнозирующую модель. В этом случае вы создадите конвейер с тремя этапами:\n",
    "1. **VectorAssembler:** Создает вектор непрерывных числовых признаков.\n",
    "\n",
    "2. **MinMaxScaler:** Нормализует непрерывные числовые характеристики.\n",
    "\n",
    "3. **Logistic Regression:** Обучает модель классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9902d64e-b8b6-49ac-a8ad-8dfba8af2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVect = VectorAssembler(inputCols = [\"elapsedDays\", \"baseFare\", \"totalFare\", \"seatsRemaining\", \"totalTravelDistance\", \"totalFlightDurationInSeconds\"], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", \n",
    "                        featuresCol=\"features\", \n",
    "                        maxIter=3,\n",
    "                        regParam=0.3)\n",
    "\n",
    "pipeline = Pipeline(stages=[numVect, minMax, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675353f4-3438-4177-9721-70efc0ef048d",
   "metadata": {},
   "source": [
    "##### Запускаем конвейер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfb68bb8-e6ac-4f74-9f05-8a2a557cdcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a1a63-a6a3-4b6a-989f-ae6913260006",
   "metadata": {},
   "source": [
    "##### Создаем предсказываемые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "827f5b16-fe73-4b3a-b03b-b0e0a7bac6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n",
      "|            features|prediction|label|\n",
      "+--------------------+----------+-----+\n",
      "|[0.0,0.0,0.0,0.4,...|       1.0|    1|\n",
      "|[0.0,0.0123483017...|       1.0|    1|\n",
      "|[0.0,0.0123483017...|       1.0|    1|\n",
      "|[0.0,0.0148179621...|       1.0|    1|\n",
      "|[0.0,0.0148179621...|       1.0|    1|\n",
      "|[0.0,0.0148179621...|       1.0|    1|\n",
      "|[0.0,0.0148179621...|       1.0|    1|\n",
      "|[0.0,0.0148179621...|       1.0|    1|\n",
      "|[0.0,0.0180710093...|       1.0|    1|\n",
      "|[0.0,0.0180710093...|       1.0|    1|\n",
      "|[0.0,0.0180710093...|       1.0|    1|\n",
      "|[0.0,0.0185357304...|       1.0|    1|\n",
      "|[0.0,0.0185357304...|       1.0|    1|\n",
      "|[0.0,0.0205406697...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "|[0.0,0.0242451602...|       1.0|    1|\n",
      "+--------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = lrModel.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"label\")\n",
    "predicted.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65af68-95a8-4aed-bfb6-27aa1b6882ed",
   "metadata": {},
   "source": [
    "##### Метрики оценки модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "373a1f38-33a9-47e2-968b-f515ae13964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|          128538.0|\n",
      "|       FP|           52597.0|\n",
      "|       TN|           81387.0|\n",
      "|       FN|           29284.0|\n",
      "|Precision|0.7096254175062798|\n",
      "|   Recall|0.8144491895933393|\n",
      "|       F1|0.7584324855365134|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND label == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND label == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND label == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND label == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872842c-0df5-45db-97eb-df5407c643ce",
   "metadata": {},
   "source": [
    "##### Оценка качества модели бинарной классификации с использованием метрики AUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69c0945b-d47b-4c05-a594-625379e1e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.8346604801319116\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(prediction)\n",
    "print (\"AUR = \", aur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678225fb-2a33-4b4c-bc0e-b0ea0cba8395",
   "metadata": {},
   "source": [
    "##### Настройка модели классификации с использованием кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "318c92e5-3f9f-4b47-a339-83c6dc1ed0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, np.arange(0, 1, 0.05)).addGrid(lr.maxIter, [5, 10]).build()\n",
    "lrcv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a00ead-46b1-43c0-a14d-a35e83cec1e8",
   "metadata": {},
   "source": [
    "##### Запускаем конвейер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3928c73-cd4c-4c00-b234-fe3aa36bb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvModel = lrcv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8006d8f-4710-4c14-9086-68156a516a27",
   "metadata": {},
   "source": [
    "##### Создаем предсказанные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e09ab1f-50a7-4ee9-a339-427793b8c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPrediction = lrcvModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda08911-e76c-47fd-9cfb-da9da28231aa",
   "metadata": {},
   "source": [
    "##### Метрики оценки обновленной модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6ea3736-4334-4ca9-b291-9141e84cceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|          151831.0|\n",
      "|       FP|            5661.0|\n",
      "|       TN|          128323.0|\n",
      "|       FN|            5991.0|\n",
      "|Precision|0.9640553170954715|\n",
      "|   Recall|0.9620395128689283|\n",
      "|       F1|0.9630463601362451|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND label == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND label == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND label == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND label == 1\").count())\n",
    "pr2 = tp2 / (tp2 + fp2)\n",
    "re2 = tp2 / (tp2 + fn2)\n",
    "metrics2 = spark.createDataFrame([\n",
    " (\"TP\", tp2),\n",
    " (\"FP\", fp2),\n",
    " (\"TN\", tn2),\n",
    " (\"FN\", fn2),\n",
    " (\"Precision\", pr2),\n",
    " (\"Recall\", re2),\n",
    " (\"F1\", 2*pr2*re2/(re2+pr2))],[\"metric\", \"value\"])\n",
    "metrics2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e15fe1-2ac9-4fe0-bb24-5b0a0b0cc12d",
   "metadata": {},
   "source": [
    "##### Оценка качества модели бинарной классификации с использованием метрики AUR после кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3321ee4-b00e-4449-a926-fc3164e69aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.959894099639623\n"
     ]
    }
   ],
   "source": [
    "newEvaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "newAur = newEvaluator.evaluate(newPrediction)\n",
    "print( \"AUR2 = \", newAur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdcbf3-fe0a-46b1-a394-e819c177becf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
